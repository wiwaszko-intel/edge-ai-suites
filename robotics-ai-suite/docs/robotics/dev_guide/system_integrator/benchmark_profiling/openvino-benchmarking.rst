OpenVINO™ Benchmarking Tool
============================

The benchmark application allows users to estimate deep learning inference performance on supported Intel® devices.
It uses the asynchronous mode to estimate deep learning inference engine performance and latency. Refer to the tutorial
that illustrates how to run the benchmark application on an Intel® Core™ processor with Intel® Iris® Xe Integrated Graphics or Intel® UHD Graphics.

* `Benchmark C++ Tool <https://docs.openvino.ai/2023.2/openvino_inference_engine_samples_benchmark_app_README.html>`__
* `Benchmark Python Tool <https://docs.openvino.ai/2023.2/openvino_inference_engine_tools_benchmark_tool_README.html>`__

.. Note::

   Performance results are based on testing as of dates shown in configurations and
   may not reflect all publicly available updates. No product or component can be
   absolutely secure. Performance varies by use, configuration and other factors.
   Learn more at `Intel® Performance Index <https://edc.intel.com/content/www/us/en/products/performance/benchmarks/>`__.

.. Note::

   To use the benchmarking tools, you first have to install OpenVINO™, following
   the instructions on the OpenVINO™ `Get Started Sample
   <https://docs.openvino.ai/2023.2/openvino_docs_get_started_get_started_demos.html>`__.
