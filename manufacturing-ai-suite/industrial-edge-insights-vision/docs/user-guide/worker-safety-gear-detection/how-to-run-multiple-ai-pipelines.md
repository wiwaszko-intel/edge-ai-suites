# Run multiple AI pipelines

In a typical deployment, multiple cameras deliver video streams that are connected to AI pipelines to improve the detection and recognition accuracy.

The DL Streamer Pipeline Server config supports multiple pipelines that you can use to launch pipeline instances. The sample application has been provided with such a config i.e. `pipeline-server-config.json`. We will use the same to demonstrate launching multiple AI pipelines.

## Steps

 The following demonstrates running two AI pipelines.
> **Note** We assume that the model and sample video is already available in the application directory under `resources/`.

1. Bring up the containers.
    ```sh
    docker compose up -d
    ```
2. Start the worker safety gear detection pipeline with the following Client URL (cURL) command by replacing the `<peer-str-id>` with a string id eg: `worker_safety1` and `<HOST_IP>` with the system IP. This pipeline is configured to run in a loop forever. This REST/cURL request will return a pipeline instance ID, which can be used as an identifier to query later the pipeline status or stop the pipeline instance. For example, a6d67224eacc11ec9f360242c0a86003.

    ``` sh
    curl -k https://<HOST_IP>/api/pipelines/user_defined_pipelines/worker_safety_gear_detection_mlops -X POST -H 'Content-Type: application/json' -d '{
        "destination": {
            "frame": {
                "type": "webrtc",
                "peer-id": "<peer-str-id>"
            }
        },
        "parameters": {
            "detection-properties": {
                "model": "/home/pipeline-server/resources/models/worker-safety-gear-detection/deployment/Detection/model/model.xml",
                "device": "CPU"
            }
        }
    }'
    ```

3. Start another worker safety gear detection pipeline with the following Client URL (cURL) command by replacing the `<different-peer-str-id>` with a different string id than the one in above step. eg: `worker_safety2` and `<HOST_IP>` with the system IP. This pipeline is not configured to run in a loop forever. This REST/cURL request will return a pipeline instance ID, which can be used as an identifier to query later the pipeline status or stop the pipeline instance. For example, a6d67224eacc11ec9f360242c0a86003.

    ``` sh
    curl -k https://<HOST_IP>/api/pipelines/user_defined_pipelines/worker_safety_gear_detection -X POST -H 'Content-Type: application/json' -d '{
        "source": {
            "uri": "file:///home/pipeline-server/resources/videos/Safety_Full_Hat_and_Vest.avi",
            "type": "uri"
        },
        "destination": {
            "frame": {
                "type": "webrtc",
                "peer-id": "<different-peer-str-id>"
            }
        },
        "parameters": {
            "detection-properties": {
                "model": "/home/pipeline-server/resources/models/worker-safety-gear-detection/deployment/Detection/model/model.xml",
                "device": "CPU"
            }
        }
    }'
    ```
    **Note the instance ID of this pipeline**

4. View the WebRTC streaming on `https://<HOST_IP>/mediamtx/<peer-str-id>/` and `https://<HOST_IP>/mediamtx/<different-peer-str-id>/`.

   ![Example of WebRTC streaming using mediamtx](./images/webrtc-streaming.png)

   Figure 1: WebRTC streaming

   > NOTE: You can also observe telemetry data from the Prometheus UI. Refer [this](./how-to-view-telemetry-data.md) document to learn more.

5. Stop the 2nd pipeline using the instance ID noted in point #3 above, before proceeding with this documentation.
   ```shell
   curl -k --location -X DELETE https://<HOST_IP>/api/pipelines/{instance_id}
   ```
